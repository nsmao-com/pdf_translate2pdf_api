# æ ¹æœ¬é—®é¢˜ä¿®å¤ï¼š'str' object has no attribute 'predict'

## ğŸ” é—®é¢˜æ ¹æºåˆ†æ

### é”™è¯¯ä¿¡æ¯
```json
{
  "error": "Translation failed: 'str' object has no attribute 'predict'",
  "status_code": 500
}
```

### æ ¹æœ¬åŸå› ï¼šå‚æ•°åå†²çª

åœ¨PDFMathTranslateé¡¹ç›®ä¸­ï¼Œå­˜åœ¨**ä¸¤ä¸ªä¸åŒç”¨é€”çš„`model`å‚æ•°**ï¼š

#### 1. æ–‡æ¡£å¸ƒå±€æ£€æµ‹çš„`model`ï¼ˆOnnxModelå¯¹è±¡ï¼‰

åœ¨ `pdf2zh/high_level.py` çš„ `translate_stream` å‡½æ•°ä¸­ï¼š

```python
def translate_stream(
    ...
    model: OnnxModel = None,  # ONNXæ¨¡å‹å¯¹è±¡ï¼Œç”¨äºæ–‡æ¡£å¸ƒå±€æ£€æµ‹
    ...
):
    ...
```

åœ¨ `translate_patch` å‡½æ•°ä¸­è¢«ä½¿ç”¨ï¼š

```python
page_layout = model.predict(image, imgsz=int(pix.height / 32) * 32)[0]
#             ^^^^^^^^^^^^^^^
#             è¿™é‡Œè°ƒç”¨OnnxModelçš„predictæ–¹æ³•
```

#### 2. LLMçš„æ¨¡å‹åï¼ˆå­—ç¬¦ä¸²ï¼‰

ä½†åœ¨æ—§ç‰ˆFastAPIä¸­ï¼Œæˆ‘ä»¬é”™è¯¯åœ°å®šä¹‰äº†ï¼š

```python
async def translate_mono(
    ...
    model: Optional[str] = Form(None, description="Model name (for LLM services)"),
    ...
):
    ...
    translate_params['model'] = model  # âŒ å­—ç¬¦ä¸²è¦†ç›–äº†OnnxModelå‚æ•°
```

å½“ä¼ é€’ `model="gpt-4o-mini"` æ—¶ï¼Œå­—ç¬¦ä¸²è¦†ç›–äº† `OnnxModel` å‚æ•°ï¼Œå¯¼è‡´ä»£ç å°è¯•ï¼š

```python
"gpt-4o-mini".predict(image, ...)  # âŒ å­—ç¬¦ä¸²æ²¡æœ‰predictæ–¹æ³•ï¼
```

---

## âœ… æ­£ç¡®çš„è®¾è®¡

### LLMæ¨¡å‹åçš„æ­£ç¡®ä¼ é€’æ–¹å¼

åœ¨ `pdf2zh/converter.py` ç¬¬157-165è¡Œï¼Œæ­ç¤ºäº†æ­£ç¡®çš„è®¾è®¡ï¼š

```python
# LLMæ¨¡å‹åé€šè¿‡serviceå‚æ•°ä¼ é€’ï¼Œæ ¼å¼ä¸º "service_name:model_name"
# ä¾‹å¦‚ï¼š
#   - "google"                 (æ— éœ€æ¨¡å‹å)
#   - "openai:gpt-4o-mini"    (OpenAI + æ¨¡å‹å)
#   - "ollama:gemma2:9b"      (Ollama + æ¨¡å‹å)

param = service.split(":", 1)
service_name = param[0]           # "openai"
service_model = param[1] if len(param) > 1 else None  # "gpt-4o-mini"

# æ¨¡å‹åä¼ é€’ç»™translator
self.translator = translator(lang_in, lang_out, service_model, ...)
```

### å‚æ•°èŒè´£åˆ†ç¦»

| å‚æ•° | ç±»å‹ | ç”¨é€” | ä¼ é€’ä½ç½® |
|------|------|------|----------|
| `service` | `str` | æŒ‡å®šç¿»è¯‘æœåŠ¡å’ŒLLMæ¨¡å‹ | APIå‚æ•° |
| `model` | `OnnxModel` | æ–‡æ¡£å¸ƒå±€æ£€æµ‹æ¨¡å‹ | å†…éƒ¨è‡ªåŠ¨åˆå§‹åŒ– |

**å…³é”®ç‚¹ï¼š**
- âœ… `service` å‚æ•°å¯ä»¥åŒ…å«æ¨¡å‹åï¼ˆç”¨å†’å·åˆ†éš”ï¼‰
- âœ… `model` å‚æ•°åº”è¯¥ç”±å†…éƒ¨ä»£ç è‡ªåŠ¨åˆå§‹åŒ–ï¼Œä¸åº”è¯¥ä»APIä¼ é€’
- âŒ ä¸åº”è¯¥æœ‰å•ç‹¬çš„ `model: str` APIå‚æ•°

---

## ğŸ”§ ä¿®å¤å†…å®¹

### 1. ç§»é™¤é”™è¯¯çš„`model`å‚æ•°

**ä¿®æ”¹å‰ï¼ˆé”™è¯¯ï¼‰ï¼š**
```python
async def translate_mono(
    file: UploadFile = File(...),
    lang_in: str = Form("en"),
    lang_out: str = Form("zh"),
    service: str = Form("google"),
    model: Optional[str] = Form(None),  # âŒ é”™è¯¯çš„å‚æ•°
    thread: int = Form(4)
):
    translate_params = {
        'lang_in': lang_in,
        'lang_out': lang_out,
        'service': service,
        'thread': thread,
    }
    if model:
        translate_params['model'] = model  # âŒ è¦†ç›–OnnxModelå‚æ•°
```

**ä¿®æ”¹åï¼ˆæ­£ç¡®ï¼‰ï¼š**
```python
async def translate_mono(
    file: UploadFile = File(...),
    lang_in: str = Form("en"),
    lang_out: str = Form("zh"),
    service: str = Form("google", description="Translation service (e.g., 'google', 'openai:gpt-4o-mini')"),
    thread: int = Form(4)
):
    translate_params = {
        'lang_in': lang_in,
        'lang_out': lang_out,
        'service': service,  # âœ… æ¨¡å‹ååœ¨serviceä¸­
        'thread': thread,
    }
    # âœ… ä¸å†ä¼ é€’modelå‚æ•°
```

### 2. æ›´æ–°çš„APIç«¯ç‚¹

æ‰€æœ‰3ä¸ªç«¯ç‚¹å·²ä¿®å¤ï¼š
- âœ… `/translate/mono` - å•è¯­ç¿»è¯‘
- âœ… `/translate/dual` - åŒè¯­ç¿»è¯‘
- âœ… `/translate` - å®Œæ•´ç¿»è¯‘ï¼ˆè¿”å›JSONï¼‰

---

## ğŸ“š APIä½¿ç”¨æŒ‡å—

### æ­£ç¡®çš„APIå‚æ•°

| å‚æ•° | å¿…éœ€ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `file` | âœ… | - | PDFæ–‡ä»¶ |
| `lang_in` | âŒ | `en` | æºè¯­è¨€ä»£ç  |
| `lang_out` | âŒ | `zh` | ç›®æ ‡è¯­è¨€ä»£ç  |
| `service` | âŒ | `google` | ç¿»è¯‘æœåŠ¡ï¼ˆå¯åŒ…å«æ¨¡å‹åï¼‰ |
| `thread` | âŒ | `4` | å¹¶å‘çº¿ç¨‹æ•°ï¼ˆ1-16ï¼‰ |

### serviceå‚æ•°æ ¼å¼

**ç®€å•æœåŠ¡ï¼ˆæ— éœ€æ¨¡å‹åï¼‰ï¼š**
```bash
service=google
service=bing
service=deepl
```

**LLMæœåŠ¡ï¼ˆéœ€è¦æ¨¡å‹åï¼‰ï¼š**
```bash
service=openai:gpt-4o-mini
service=openai:gpt-4
service=ollama:gemma2:9b
service=ollama:llama3:8b
service=gemini:gemini-pro
service=zhipu:glm-4
```

---

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šä½¿ç”¨Googleç¿»è¯‘ï¼ˆå…è´¹ï¼‰

```bash
curl -X POST http://localhost:11200/translate/mono \
  -F "file=@document.pdf" \
  -F "lang_in=en" \
  -F "lang_out=zh" \
  -F "service=google" \
  --output translated.pdf
```

### ç¤ºä¾‹2ï¼šä½¿ç”¨OpenAI GPT-4o-mini

```bash
curl -X POST http://localhost:11200/translate/mono \
  -F "file=@document.pdf" \
  -F "lang_in=en" \
  -F "lang_out=zh" \
  -F "service=openai:gpt-4o-mini" \
  -F "thread=8" \
  --output translated.pdf
```

### ç¤ºä¾‹3ï¼šä½¿ç”¨Ollamaæœ¬åœ°æ¨¡å‹

```bash
curl -X POST http://localhost:11200/translate/mono \
  -F "file=@document.pdf" \
  -F "lang_in=en" \
  -F "lang_out=zh" \
  -F "service=ollama:gemma2:9b" \
  --output translated.pdf
```

### ç¤ºä¾‹4ï¼šåŒè¯­ç‰ˆæœ¬

```bash
curl -X POST http://localhost:11200/translate/dual \
  -F "file=@document.pdf" \
  -F "service=openai:gpt-4o-mini" \
  --output translated_dual.pdf
```

---

## ğŸ Pythonè°ƒç”¨ç¤ºä¾‹

### æ­£ç¡®çš„Pythonä»£ç 

```python
import requests

def translate_pdf(
    input_file: str,
    output_file: str,
    service: str = "google",
    lang_in: str = "en",
    lang_out: str = "zh",
    thread: int = 4
):
    """
    ç¿»è¯‘PDFæ–‡ä»¶

    Args:
        input_file: è¾“å…¥PDFè·¯å¾„
        output_file: è¾“å‡ºPDFè·¯å¾„
        service: ç¿»è¯‘æœåŠ¡ï¼Œæ ¼å¼ï¼š
            - ç®€å•: "google", "bing", "deepl"
            - LLM: "openai:gpt-4o-mini", "ollama:gemma2:9b"
        lang_in: æºè¯­è¨€
        lang_out: ç›®æ ‡è¯­è¨€
        thread: çº¿ç¨‹æ•°
    """
    url = 'http://localhost:11200/translate/mono'

    with open(input_file, 'rb') as f:
        files = {'file': f}
        data = {
            'lang_in': lang_in,
            'lang_out': lang_out,
            'service': service,  # âœ… æ¨¡å‹ååœ¨serviceä¸­
            'thread': thread,
        }

        response = requests.post(url, files=files, data=data)

        if response.status_code == 200:
            with open(output_file, 'wb') as out:
                out.write(response.content)
            print(f"âœ… ç¿»è¯‘æˆåŠŸ: {output_file}")
            return True
        else:
            print(f"âŒ ç¿»è¯‘å¤±è´¥: {response.json()}")
            return False

# ä½¿ç”¨ç¤ºä¾‹
translate_pdf('paper.pdf', 'paper_zh.pdf', service='google')
translate_pdf('paper.pdf', 'paper_zh_gpt.pdf', service='openai:gpt-4o-mini')
translate_pdf('paper.pdf', 'paper_zh_local.pdf', service='ollama:gemma2:9b')
```

### âŒ é”™è¯¯ç¤ºä¾‹ï¼ˆæ—§ç‰ˆæœ¬ï¼‰

```python
# âŒ ä¸è¦è¿™æ ·åšï¼
data = {
    'lang_in': 'en',
    'lang_out': 'zh',
    'service': 'openai',      # âŒ é”™è¯¯ï¼šåˆ†ç¦»äº†æœåŠ¡å’Œæ¨¡å‹
    'model': 'gpt-4o-mini',   # âŒ é”™è¯¯ï¼šmodelå‚æ•°å·²ç§»é™¤
    'thread': 4,
}
```

---

## ğŸ”§ åº”ç”¨ä¿®å¤

### æ­¥éª¤1ï¼šåœæ­¢æ—§å®¹å™¨

```bash
cd D:\2024Dev\PDFMathTranslate-main
docker-compose -f docker-compose.fastapi.yml down
```

### æ­¥éª¤2ï¼šé‡æ–°æ„å»º

```bash
docker-compose -f docker-compose.fastapi.yml up --build -d
```

### æ­¥éª¤3ï¼šéªŒè¯ä¿®å¤

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:11200/health

# æµ‹è¯•Googleç¿»è¯‘
curl -X POST http://localhost:11200/translate/mono \
  -F "file=@test.pdf" \
  -F "service=google" \
  --output test_zh.pdf

# æµ‹è¯•OpenAIç¿»è¯‘ï¼ˆéœ€è¦é…ç½®APIå¯†é’¥ï¼‰
curl -X POST http://localhost:11200/translate/mono \
  -F "file=@test.pdf" \
  -F "service=openai:gpt-4o-mini" \
  --output test_zh_gpt.pdf
```

---

## ğŸ“Š æ”¯æŒçš„æœåŠ¡å’Œæ¨¡å‹

### å…è´¹æœåŠ¡
- `google` - Googleç¿»è¯‘
- `bing` - Microsoft Bingç¿»è¯‘
- `deepl` - DeepLç¿»è¯‘ï¼ˆå…è´¹ç‰ˆï¼‰
- `deeplx` - DeepL X

### LLMæœåŠ¡ï¼ˆéœ€è¦APIå¯†é’¥ï¼‰

| æœåŠ¡ | æ ¼å¼ç¤ºä¾‹ | è¯´æ˜ |
|------|----------|------|
| OpenAI | `openai:gpt-4o-mini` | éœ€è¦OPENAI_API_KEY |
| Gemini | `gemini:gemini-pro` | éœ€è¦GEMINI_API_KEY |
| Anthropic | `anthropic:claude-3-haiku` | éœ€è¦ANTHROPIC_API_KEY |
| Zhipu | `zhipu:glm-4` | éœ€è¦ZHIPU_API_KEY |
| DeepSeek | `deepseek:deepseek-chat` | éœ€è¦DEEPSEEK_API_KEY |
| Ollama | `ollama:gemma2:9b` | éœ€è¦æœ¬åœ°OllamaæœåŠ¡ |

### é…ç½®APIå¯†é’¥

é€šè¿‡ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ï¼š

```bash
# ç¯å¢ƒå˜é‡æ–¹å¼
docker run -d \
  -p 11200:8000 \
  -e OPENAI_API_KEY=sk-your-key \
  -e GEMINI_API_KEY=your-key \
  pdf2zh-api
```

æˆ–ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼š`~/.config/PDFMathTranslate/config.json`

---

## âœ… ä¿®å¤æ¸…å•

- [x] ç§»é™¤æ‰€æœ‰ç«¯ç‚¹çš„ `model` å‚æ•°
- [x] æ›´æ–° `service` å‚æ•°è¯´æ˜ï¼ˆæ”¯æŒå†’å·åˆ†éš”çš„æ¨¡å‹åï¼‰
- [x] ç§»é™¤ `translate_params` ä¸­çš„modelå¤„ç†é€»è¾‘
- [x] æ›´æ–°APIæ–‡æ¡£è¯´æ˜
- [x] åˆ›å»ºè¯¦ç»†çš„ä¿®å¤æŒ‡å—

---

## ğŸ‰ æ€»ç»“

**æ ¸å¿ƒé—®é¢˜ï¼š** å‚æ•°åå†²çªå¯¼è‡´å­—ç¬¦ä¸²è¦†ç›–OnnxModelå¯¹è±¡

**æ ¹æœ¬è§£å†³ï¼š** ç§»é™¤ç‹¬ç«‹çš„`model`å‚æ•°ï¼Œé€šè¿‡`service`å‚æ•°ä¼ é€’LLMæ¨¡å‹å

**æ­£ç¡®æ ¼å¼ï¼š** `service="service_name:model_name"`

**ä¿®å¤åï¼š** APIæ›´ç®€æ´ï¼Œå‚æ•°èŒè´£æ›´æ¸…æ™°ï¼Œä¸å†æœ‰å†²çª

---

**ä¿®å¤å®Œæˆæ—¥æœŸï¼š** 2025-11-03
**ä¿®å¤ç‰ˆæœ¬ï¼š** v1.9.11+fix3

å¦‚æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·å‚è€ƒ `DOCKER_DEPLOYMENT_README.md`ã€‚
